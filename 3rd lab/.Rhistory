View(diabetes)
diabetes <- read.csv("D:/Sem study materials/study materials 6th sem/Study materials by me/Statistical Learning Lab/3rd lab/diabetes.csv")
View(diabetes)
View(df)
df <- diabetes
View(df)
head(df)
View(diabetes)
df <- diabetes
View(df)
head(df)
dim(df)
str(df)
plot(df)
table(df)
table(df$Pregnancies)
plot(df)
boxplot(Outcome ~ Glucose, data = df)
boxplot(Glucose ~ Outcome , data = df)
library(ggplot2)
ggplot(diabetes, aes(x = Glucose, y = Outcome)) +
geom_jitter(alpha = 0.5, color = "blue") +
labs(title = "Scatter Plot: Glucose vs Outcome", x = "Glucose", y = "Outcome")
ggplot(diabetes, aes(x = Insulin, y = Outcome)) +
geom_jitter(alpha = 0.5, color = "blue") +
labs(title = "Scatter Plot: Glucose vs Outcome", x = "Glucose", y = "Outcome")
ggplot(diabetes, aes(x = Glucose, y = Outcome)) +
geom_jitter(alpha = 0.5, color = "blue") +
labs(title = "Scatter Plot: Glucose vs Outcome", x = "Glucose", y = "Outcome")
ggplot(diabetes, aes(x = DiabetesPedigreeFunction, y = Outcome)) +
geom_jitter(alpha = 0.5, color = "blue") +
labs(title = "Scatter Plot: Glucose vs Outcome", x = "Glucose", y = "Outcome")
ggplot(diabetes, aes(x = DiabetesPedigreeFunction, y = Outcome)) +
geom_jitter(alpha = 0.5, color = "blue") +
labs(title = "Scatter Plot: DiabetesPedigreeFunction vs Outcome", x = "DiabetesPedigreeFunction", y = "Outcome")
ggplot(diabetes, aes(x = factor(Outcome), y = BMI, fill = factor(Outcome))) +
geom_boxplot() +
labs(title = "Box Plot: BMI vs Outcome", x = "Outcome", y = "BMI") +
theme_minimal()
num_data <- df[,sapply(df,is.numeric)] #select numeric columns
cor_matrix <- cor(num_data , use = "complete.obs")
print(cor_matrix)
?plot(BMI ~ Glucose, data = df,  )
?plot(BMI ~ Glucose, data = df,main = Outcome  )
plot(BMI ~ Glucose, data = df,main = Outcome  )
plot(BMI ~ Glucose, data = df,sub = Outcome  )
ggplot(diabetes, aes(x = Glucose, y = BMI, shape = factor(Outcome))) +
geom_point(size = 3, alpha = 0.7) +  # Points with different shapes based on Outcome
labs(
title = "Scatter Plot: Glucose vs BMI by Outcome",
x = "Glucose",
y = "BMI",
shape = "Outcome"
) +
theme_minimal() +  # Minimal theme for a clean look
scale_shape_manual(values = c(16, 17))
ggplot(diabetes, aes(x = Glucose, y = BMI, shape = factor(Outcome))) +
geom_point(size = 3, alpha = 0.7) +  # Points with different shapes based on Outcome
labs(
title = "Scatter Plot: Glucose vs BMI by Outcome",
x = "Glucose",
y = "BMI",
shape = "Outcome"
) +
theme_minimal() +  # Minimal theme for a clean look
scale_shape_manual(values = c(16, 87))
ggplot(diabetes, aes(x = Glucose, y = BMI, shape = factor(Outcome))) +
geom_point(size = 3, alpha = 0.7) +  # Points with different shapes based on Outcome
labs(
title = "Scatter Plot: Glucose vs BMI by Outcome",
x = "Glucose",
y = "BMI",
shape = "Outcome"
) +
theme_minimal() +  # Minimal theme for a clean look
scale_shape_manual(values = c(16, 12))
ggplot(diabetes, aes(x = Glucose, y = BMI, shape = factor(Outcome))) +
geom_point(size = 3, alpha = 0.7) +  # Points with different shapes based on Outcome
labs(
title = "Scatter Plot: Glucose vs BMI by Outcome",
x = "Glucose",
y = "BMI",
shape = "Outcome"
) +
theme_minimal() +  # Minimal theme for a clean look
scale_shape_manual(values = c(16, 18))
ggplot(diabetes, aes(x = Glucose, y = BMI, shape = factor(Outcome))) +
?geom_point(size = 3, alpha = 0.7,) +  # Points with different shapes based on Outcome
labs(
title = "Scatter Plot: Glucose vs BMI by Outcome",
x = "Glucose",
y = "BMI",
shape = "Outcome"
) +
theme_minimal() +  # Minimal theme for a clean look
scale_shape_manual(values = c(16, 18))
?ggplot(diabetes, aes(x = Glucose, y = BMI, shape = factor(Outcome))) +
geom_point(size = 3, alpha = 0.7,) +  # Points with different shapes based on Outcome
labs(
title = "Scatter Plot: Glucose vs BMI by Outcome",
x = "Glucose",
y = "BMI",
shape = "Outcome"
) +
theme_minimal() +  # Minimal theme for a clean look
scale_shape_manual(values = c(16, 18))
# Print the plot
print(p)
# Loop through all combinations of input variables with Outcome
for (x_col in input_columns) {
for (y_col in input_columns) {
if (x_col != y_col) {
# Scatter plot for each combination
p <- ggplot(diabetes, aes_string(x = x_col, y = y_col, color = "factor(Outcome)", shape = "factor(Outcome)")) +
geom_point(size = 3, alpha = 0.7) +
labs(
title = paste("Scatter Plot:", x_col, "vs", y_col, "by Outcome"),
x = x_col,
y = y_col,
color = "Outcome",
shape = "Outcome"
) +
theme_minimal() +
scale_color_manual(values = c("blue", "red")) +  # Colors for Outcome
scale_shape_manual(values = c(16, 17))          # Shapes for Outcome
# Print the plot
print(p)
}
}
}
# Define the input columns (exclude the Outcome column)
input_columns <- c("Glucose", "BMI", "BloodPressure", "SkinThickness", "Insulin",
"Pregnancies", "DiabetesPedigreeFunction", "Age")
# Loop through all combinations of input variables with Outcome
for (x_col in input_columns) {
for (y_col in input_columns) {
if (x_col != y_col) {
# Scatter plot for each combination
p <- ggplot(diabetes, aes_string(x = x_col, y = y_col, color = "factor(Outcome)", shape = "factor(Outcome)")) +
geom_point(size = 3, alpha = 0.7) +
labs(
title = paste("Scatter Plot:", x_col, "vs", y_col, "by Outcome"),
x = x_col,
y = y_col,
color = "Outcome",
shape = "Outcome"
) +
theme_minimal() +
scale_color_manual(values = c("blue", "red")) +  # Colors for Outcome
scale_shape_manual(values = c(16, 17))          # Shapes for Outcome
# Print the plot
print(p)
}
}
}
# Scatter plot for each combination
p <- ggplot(diabetes, aes_string(x = x_col, y = y_col, color = "factor(Outcome)", shape = "factor(Outcome)")) +
geom_point(size = 3, alpha = 0.7) +
labs(
title = paste("Scatter Plot:", x_col, "vs", y_col, "by Outcome"),
x = x_col,
y = y_col,
color = "Outcome",
shape = "Outcome"
) +
theme_minimal() +
scale_color_manual(values = c("blue", "red")) +  # Colors for Outcome
scale_shape_manual(values = c(16, 17))          # Shapes for Outcome
# Print the plot
print(p)
# Define the input columns (exclude the Outcome column)
input_columns <- c("Glucose", "BMI", "BloodPressure", "SkinThickness", "Insulin",
"Pregnancies", "DiabetesPedigreeFunction", "Age")
# Start saving plots to a PDF file
pdf("scatter_plots_outcome.pdf", width = 8, height = 6)  # Specify file name and dimensions
# Loop through all combinations of input variables with Outcome
for (x_col in input_columns) {
for (y_col in input_columns) {
if (x_col != y_col) {
# Scatter plot for each combination
p <- ggplot(diabetes, aes_string(x = x_col, y = y_col, color = "factor(Outcome)", shape = "factor(Outcome)")) +
geom_point(size = 3, alpha = 0.7) +
labs(
title = paste("Scatter Plot:", x_col, "vs", y_col, "by Outcome"),
x = x_col,
y = y_col,
color = "Outcome",
shape = "Outcome"
) +
theme_minimal() +
scale_color_manual(values = c("blue", "red")) +  # Colors for Outcome
scale_shape_manual(values = c(16, 17))          # Shapes for Outcome
# Print the plot to the PDF
print(p)
}
}
}
# Stop writing to the PDF
dev.off()
# Message to confirm completion
cat("Scatter plots have been saved to 'scatter_plots_outcome.pdf' in your working directory.\n")
ggplot(diabetes, aes(x = factor(Outcome), y = Insulin, fill = factor(Outcome))) +
geom_boxplot() +
labs(title = "Box Plot: Insulin vs Outcome", x = "Outcome", y = "Insulin") +
theme_minimal()
trn <- sample(dim(df)[1], 615) # 80% of 768
trn
Default_train <- df[trn,]
Default_test <- df[-trn,]
df_train <- df[trn,]
df_test <- df[-trn,]
head(df_test)
df_test <- df[,-1]
head(df_test)
df_test <- df[-trn,]
head(df_test)
df_test <- subset(df_test,select = -`Outcome`)
head(df_test)
dim(df_train)
dim(df_test)
#fit logistic regression model
glm.fits = glm(Outcome ~. , family = binomial , data = df_train)
summary(glm.fits)
#Create confusion matrix
table(Default[-trn,]$default , pred_class)
library(ISLR2)
head(Default)
library(stats)
log_likelihood <- logLik(glm.fits)
log_likelihood
#Create confusion matrix
table(Default[-trn,]$default , pred_class)
#Classify the prediction in default = "Yes" or "No"
pred_class <- ifelse(pred>=0.5 , "Yes" , "No")
#fit llogistic regression model
glm.fit2 = glm(default~ student + balance , family = binomial , data = Default_train)
#predict using test dataset
pred <- predict(glm.fit2 , Default_test , type = "response")
pred <- predict(glm.fit2 , df_test , type = "response")
pred <- predict(glm.fits , df_test , type = "response")
pred_class <- ifelse(pred>=0.5 , 1 , 0)
#Create confusion matrix
table(df[-trn,]$Outcome , pred_class)
#Test Accuracy
mean(pred_class == df[-trn,]$Outcome)
#Create confusion matrix
conf_matrix <- table(df[-trn,]$Outcome , pred_class)
tp <- conf_matrix$table[2, 2]  # True Positives
tp <- conf_matrix[2, 2]  # True Positives
tp# True Positives
tp <- conf_matrix[2, 2]        # True Positives
fp <- conf_matrix[1, 2]  # False Positives
fn <- conf_matrix[2, 1]  # False Negatives
# Precision
precision <- tp / (tp + fp)
# Recall
recall <- tp / (tp + fn)
# F1-Score
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1-Score:", f1_score, "\n")
glm.fit2 = glm(Outcome ~ Pregnancies + Glucose + BMI  , family = binomial , data = df_train)
M1  = glm(Outcome ~. , family = binomial , data = df_train)
M2 = glm(Outcome ~ Pregnancies + Glucose + BMI  , family = binomial , data = df_train)
summary(M2)
deviance(M1) - deviance(M2)
dof = 8 - 3
qchisq(0.95,dof)
chisquare = deviance(M1) - deviance(M2)
ggplot(boxplot_data, aes(x= as.factor(Outcome), y = Value , fill=as.factor(Outcome))) +geom_boxplot() + facet_wrap(~Variable , scales = "free") + theme_minimal() + labs(x = "Outcome" , y= "Value" , fill = "Outcome")
# Load required library
library(ggplot2)
ggplot(boxplot_data, aes(x= as.factor(Outcome), y = Value , fill=as.factor(Outcome))) +geom_boxplot() + facet_wrap(~Variable , scales = "free") + theme_minimal() + labs(x = "Outcome" , y= "Value" , fill = "Outcome")
qchisq(0.95,dof)(cols = -Outcome , names_to = "variable", values_to = "Value")
library(caret)
install.packages("caret")
library(caret)
library(caret)
boxplot_data <- diabetes%>% pivot_longer
library(dplyr)
library(dplyr)
boxplot_data <- diabetes%>% pivot_longer
library(tidyr)
boxplot_data <- diabetes%>% pivot_longer
boxplot_data <- diabetes%>% pivot_longer(cols = -Outcome , names_to = "Variable", values_to = "Value")
ggplot(boxplot_data, aes(x= as.factor(Outcome), y = Value , fill=as.factor(Outcome))) +geom_boxplot() + facet_wrap(~Variable , scales = "free") + theme_minimal() + labs(x = "Outcome" , y= "Value" , fill = "Outcome")
library(ISLR)
head(Smarket)
attach(Smarket)
unique(Direction)
unique(Year)
dim(Smarket)
?Smarket
?df
?diabetes
library(ggplot2)
ggplot(Smarket ,aes(x=Direction,y= Volume , fill = Direction)) + geom_boxplot()
ggplot(Smarket ,aes(x=Volume,y= Direction , fill = Direction)) + geom_boxplot()
ggplot(Smarket ,aes(x=Volume )) + geom_histogram()
ggplot(Smarket ,aes(x=Volume , fill = Volume )) + geom_histogram()
lda_fit <- lada(Direction ~ Lag1 + Lag2, data = Smarket , subset = Year<2005)
lda_fit <- lda(Direction ~ Lag1 + Lag2, data = Smarket , subset = Year<2005)
library(MASS)
lda_fit <- lda(Direction ~ Lag1 + Lag2, data = Smarket , subset = Year<2005)
lda_fit
par(mar = c(1,1,1,1))
plot(lda_fit)
subset.2005 <- subset(Smarket, Year == 2005)
pred <- predict(lda_fit , newdata= subset.2005)
head(pred.df)
pred.df <- data.frame(pred)
head(pred.df)
?predict.lda
table(subset.2005$Direction, pred.df$class)
table(Actual = subset.2005$Direction,Predicted = pred.df$class)
library(MASS)
library(ggplot2)
attach(iris)
str(iris)
head(iris)
# Scaling the dataset
iris[1:4] <- scale(iris[1:4])
head(iris)
View(diabetes)
# To returns a vector of the means and standard deviation of the variables
set.seed(1)
sample <- sample(c(TRUE , FALSE) , nrow(iris),replace = TRUE,prob = c(0.7,0.3))
sample
test <- iris[!sample,]
model <- lda(Species~.,data = train)
# train and test sample
train <- iris[sample,]
model <- lda(Species~.,data = train)
model
#Quadratic discriminant analysis
qmodel <- qda(Species~., data = train)
qmodel
qpredicted <- predict(qmodel,test)
qp1 <- predict(qmodel, train)$class
qp1
qtab <- table(Predicted = qp1 , Actual = train$Species)
qtab
qp2 <- predict(qmodel, test)$class
qp2
qtab <- table(Predicted = qp2 , Actual = test$Species)
qtab1 <- table(Predicted = qp2 , Actual = test$Species)
qtab
sum(diag(qtab1))/sum(qtab1)
library(MASS)
library(ggplot2)
install.packages("caTools")
library(caTools)
library(dplyr)
library(dplyr)
library(class)
library(MASS)
Default
head(Default)
str(Default)
set.seed(10000)
# Unlike many of our previous methods, knn() required
Default$student = as.numeric(Default$student)  - 1
Default$student
head(Default)
default_index = sample(nrow(Default),5000)
dim(Default)
default_train = Default[default_index,]
default_train = Default[-default_index,]
default_test = Default[-default_index,]
default_index = sample(nrow(Default),5000)
default_train = Default[default_index,]
default_test = Default[-default_index,]
# training data
X_default_train = default_train[,-1]
y_default_train = default_train$default
dim(y_default_train)
X_default_test = default_test[,-1]
y_default_test = default_test$default
predicted = knn(train = X_default_train,test = X_default_test, cl = y_default_train,k = 50)
predicted1 = knn(train = X_default_train,test = X_default_test, cl = y_default_train,k = 50)
predicted2 = knn(train = X_default_train, test = X_default_test , cl = y_default_train, k = 100)
df <- diabetes
head(df)
df <- diabetes
head(df)
library(caret)
library(caret)
accuracy = confutsionMatrix(predicted, y_default_test)$overall["Accuracy"]
accuracy = confusionMatrix(predicted, y_default_test)$overall["Accuracy"]
accuracy
accuracy = confusionMatrix(predicted2, y_default_test)$overall["Accuracy"]
accuracy
predicted2 = knn(train = X_default_train, test = X_default_test , cl = y_default_train, k = 100)
library(caret)
accuracy = confusionMatrix(predicted2, y_default_test)$overall["Accuracy"]
accuracy
set.seed(42)
k_to_try = 1:100
acc_k = rep(x = 0 , times = length(k_to_try))
# calculate accuracy using confusion matrix
cm = confusionMatrix(pred, y_default_test)
for(i in seq_along(k_to_try)){
pred = knn(train = scale(X_default_train),test = scale(X_default_test), cl = y_default_train , k= k_to_try[i])
# calculate accuracy using confusion matrix
cm = confusionMatrix(pred, y_default_test)
acc_k[i] = cm$overall["Accuracy"]
}
acc_k
cor(Default)
#Exploratory Data Analysis using boxplot
boxplot(balance ~ default)
boxplot(income ~ default)
ggplot(Default , aes(x=default , y= balance , fill = default)) + geom_boxplot()
library(MASS)
library(ggplot2)
attach(iris)
str(iris)
head(iris)
iris[1:4] <- scale(iris[1:4]) # Standardization , Lda ke liye must hai scaling but not for qda
head(iris)
set.seed(1)
sample <- sample(c(TRUE , FALSE) , nrow(iris),replace = TRUE,prob = c(0.7,0.3))
sample
# train and test sample
train <- iris[sample,]
test <- iris[!sample,]
model <- lda(Species~.,data = train)
model
qmodel <- qda(Species~., data = train)
qmodel
qpredicted <- predict(qmodel,test)
qp1 <- predict(qmodel, train)$class
qp1
qtab <- table(Predicted = qp1 , Actual = train$Species)
qtab
qp2 <- predict(qmodel, test)$class
qp2
qtab1 <- table(Predicted = qp2 , Actual = test$Species)
qtab
sum(diag(qtab1))/sum(qtab1)
